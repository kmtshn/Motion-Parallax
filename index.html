<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Head-Coupled Perspective Illusion</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            overflow: hidden;
            background-color: #050505;
            color: #fff;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            touch-action: none;
        }
        #canvas-container {
            width: 100vw;
            height: 100vh;
            display: block;
        }
        #ui-layer {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            background-color: rgba(0, 0, 0, 0.8);
            z-index: 10;
            transition: opacity 0.5s;
        }
        h1 {
            font-size: 1.5rem;
            margin-bottom: 10px;
            text-align: center;
            color: #00ffcc;
        }
        p {
            font-size: 1rem;
            margin-bottom: 30px;
            text-align: center;
            max-width: 80%;
            line-height: 1.5;
        }
        button {
            padding: 15px 30px;
            font-size: 1.2rem;
            background-color: #00ffcc;
            color: #000;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            font-weight: bold;
            box-shadow: 0 4px 15px rgba(0, 255, 204, 0.4);
            transition: transform 0.2s, background-color 0.2s;
        }
        button:hover {
            transform: scale(1.05);
            background-color: #33ffdb;
        }
        button:disabled {
            background-color: #555;
            color: #888;
            cursor: not-allowed;
            box-shadow: none;
        }
        #webcam {
            display: none; /* 画面には表示しない */
        }
        #loading {
            display: none;
            margin-top: 15px;
            color: #00ffcc;
            font-size: 0.9rem;
        }
    </style>
    <!-- Three.js の読み込み -->
    <script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>
    <script type="importmap">
      {
        "imports": {
          "three": "https://cdn.jsdelivr.net/npm/three@0.154.0/build/three.module.js",
          "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs"
        }
      }
    </script>
</head>
<body>

    <div id="ui-layer">
        <h1>3Dウィンドウ錯視</h1>
        <p>インカメラを使用して顔の位置をトラッキングし、<br>画面の奥に空間があるような錯覚を生み出します。</p>
        <button id="start-btn">カメラを起動して開始</button>
        <div id="loading">AIモデルを読み込み中...</div>
    </div>

    <!-- トラッキング用カメラ（非表示） -->
    <video id="webcam" autoplay playsinline></video>

    <div id="canvas-container"></div>

    <script type="module">
        import * as THREE from 'three';
        import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';

        // --- ログのフィルタリング処理 ---
        // MediaPipe(WASM)内部から出力される正常なINFOログが、エラーとしてコンソールを汚すのを防ぐためのハック
        const originalConsoleError = console.error;
        const originalConsoleWarn = console.warn;
        
        console.error = function(...args) {
            if (typeof args[0] === 'string' && args[0].includes('TensorFlow Lite XNNPACK delegate')) return;
            originalConsoleError.apply(console, args);
        };
        console.warn = function(...args) {
            if (typeof args[0] === 'string' && args[0].includes('TensorFlow Lite XNNPACK delegate')) return;
            originalConsoleWarn.apply(console, args);
        };


        // --- DOM要素の取得 ---
        const uiLayer = document.getElementById('ui-layer');
        const startBtn = document.getElementById('start-btn');
        const loadingText = document.getElementById('loading');
        const video = document.getElementById('webcam');
        const container = document.getElementById('canvas-container');

        // --- 設定値 ---
        // 仮想スクリーンのサイズ（基準幅を100とする）
        const SCREEN_W = 100;
        let SCREEN_H = SCREEN_W * (window.innerHeight / window.innerWidth);
        const BOX_DEPTH = 250; // 部屋の奥行き（より深くして没入感をアップ）

        // --- Three.js セットアップ ---
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x050505);

        // カメラ（初期設定。毎フレーム計算し直します）
        const camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 1, 1000);
        
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        container.appendChild(renderer.domElement);

        // --- 3D空間の作成（サイバーパンク風ワイヤーフレームの部屋） ---
        const roomGroup = new THREE.Group();
        scene.add(roomGroup);

        const gridColor = 0x00ffcc;
        // グリッドの密度を上げて側面を埋める
        const backDivisions = 20;
        const sideDivisions = 40; 

        // 奥の壁
        const backGrid = new THREE.GridHelper(SCREEN_W, backDivisions, gridColor, gridColor);
        backGrid.rotation.x = Math.PI / 2;
        backGrid.position.z = -BOX_DEPTH;
        // アスペクト比に合わせてスケール
        backGrid.scale.z = SCREEN_H / SCREEN_W;
        roomGroup.add(backGrid);

        // 床
        const bottomGrid = new THREE.GridHelper(SCREEN_W, sideDivisions, gridColor, gridColor);
        bottomGrid.position.y = -SCREEN_H / 2;
        bottomGrid.position.z = -BOX_DEPTH / 2;
        bottomGrid.scale.z = BOX_DEPTH / SCREEN_W;
        roomGroup.add(bottomGrid);

        // 天井
        const topGrid = new THREE.GridHelper(SCREEN_W, sideDivisions, gridColor, gridColor);
        topGrid.position.y = SCREEN_H / 2;
        topGrid.position.z = -BOX_DEPTH / 2;
        topGrid.scale.z = BOX_DEPTH / SCREEN_W;
        roomGroup.add(topGrid);

        // 左の壁
        const leftGrid = new THREE.GridHelper(SCREEN_H, sideDivisions, gridColor, gridColor);
        leftGrid.rotation.z = Math.PI / 2;
        leftGrid.position.x = -SCREEN_W / 2;
        leftGrid.position.z = -BOX_DEPTH / 2;
        leftGrid.scale.x = BOX_DEPTH / SCREEN_H;
        roomGroup.add(leftGrid);

        // 右の壁
        const rightGrid = new THREE.GridHelper(SCREEN_H, sideDivisions, gridColor, gridColor);
        rightGrid.rotation.z = Math.PI / 2;
        rightGrid.position.x = SCREEN_W / 2;
        rightGrid.position.z = -BOX_DEPTH / 2;
        rightGrid.scale.x = BOX_DEPTH / SCREEN_H;
        roomGroup.add(rightGrid);

        // 浮遊するオブジェクト（奥行き感を強調するため）
        const objGeometry = new THREE.IcosahedronGeometry(8, 1);
        const objMaterial = new THREE.MeshBasicMaterial({ color: 0xff00ff, wireframe: true });
        const floatingObj1 = new THREE.Mesh(objGeometry, objMaterial);
        floatingObj1.position.set(-15, 0, -50);
        roomGroup.add(floatingObj1);

        const objGeometry2 = new THREE.BoxGeometry(10, 10, 10);
        const objMaterial2 = new THREE.MeshBasicMaterial({ color: 0xffff00, wireframe: true });
        const floatingObj2 = new THREE.Mesh(objGeometry2, objMaterial2);
        floatingObj2.position.set(20, -10, -100);
        roomGroup.add(floatingObj2);

        // 部屋の枠線（窓枠）
        const edges = new THREE.EdgesGeometry(new THREE.BoxGeometry(SCREEN_W, SCREEN_H, BOX_DEPTH));
        const line = new THREE.LineSegments(edges, new THREE.LineBasicMaterial({ color: 0xffffff, opacity: 0.8, transparent: true }));
        line.position.z = -BOX_DEPTH / 2;
        roomGroup.add(line);


        // --- トラッキング用の変数 ---
        let faceLandmarker;
        let runningMode = "VIDEO";
        let lastVideoTime = -1;
        
        // カメラ（目）の目標位置と現在の位置（滑らかに移動させるためLERPを使用）
        const DEFAULT_Z = 60; // 画面から顔までのデフォルト距離
        let targetEyePos = new THREE.Vector3(0, 0, DEFAULT_Z);
        let currentEyePos = new THREE.Vector3(0, 0, DEFAULT_Z);


        // --- オフアクシス投影（非対称視錐台）の計算関数 ---
        // ユーザーの視点に合わせて、画面の枠が物理的な窓枠に一致するようにパースを歪ませます
        function applyOffAxisProjection(camera, eyePosition, screenW, screenH, near, far) {
            // Z値が0以下になると投影が破綻するため防ぐ
            const z = Math.max(eyePosition.z, near);

            // 視点から画面エッジまでの距離を計算（Nearクリップ面でスケーリング）
            const left   = (-screenW / 2 - eyePosition.x) * near / z;
            const right  = ( screenW / 2 - eyePosition.x) * near / z;
            const bottom = (-screenH / 2 - eyePosition.y) * near / z;
            const top    = ( screenH / 2 - eyePosition.y) * near / z;

            // 投影行列を強制的に上書き
            camera.projectionMatrix.makePerspective(left, right, top, bottom, near, far);
            // カメラ自体を目の位置へ移動
            camera.position.copy(eyePosition);
        }

        // --- MediaPipe Face Landmarker の初期化 ---
        async function initFaceLandmarker() {
            try {
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
                );
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                        delegate: "GPU"
                    },
                    outputFaceBlendshapes: false,
                    runningMode: runningMode,
                    numFaces: 1
                });
                return true;
            } catch (error) {
                console.error("Face Landmarkerの初期化に失敗しました:", error);
                alert("AIモデルの読み込みに失敗しました。再読み込みしてください。");
                return false;
            }
        }

        // --- ウェブカメラの起動 ---
        async function enableCam() {
            startBtn.disabled = true;
            startBtn.innerText = "起動中...";
            loadingText.style.display = "block";

            // AIモデルのロード
            const isModelLoaded = await initFaceLandmarker();
            if (!isModelLoaded) {
                startBtn.disabled = false;
                startBtn.innerText = "再試行";
                return;
            }

            // カメラの取得
            const constraints = {
                video: {
                    facingMode: "user", // インカメラを優先
                    width: { ideal: 640 },
                    height: { ideal: 480 }
                }
            };

            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    // カメラ準備完了、UIを隠して描画開始
                    uiLayer.style.opacity = "0";
                    setTimeout(() => uiLayer.style.display = "none", 500);
                    renderLoop();
                });
            } catch (err) {
                console.error("カメラへのアクセスが拒否されたか、エラーが発生しました:", err);
                alert("カメラの許可が必要です。ブラウザの設定を確認してください。");
                startBtn.disabled = false;
                startBtn.innerText = "カメラを起動して開始";
                loadingText.style.display = "none";
            }
        }

        startBtn.addEventListener('click', enableCam);

        // --- メイン描画ループ ---
        function renderLoop() {
            requestAnimationFrame(renderLoop);

            // 1. 顔のトラッキング
            if (faceLandmarker && video.readyState >= 2) {
                let startTimeMs = performance.now();
                if (lastVideoTime !== video.currentTime) {
                    lastVideoTime = video.currentTime;
                    const results = faceLandmarker.detectForVideo(video, startTimeMs);
                    
                    if (results.faceLandmarks && results.faceLandmarks.length > 0) {
                        const landmarks = results.faceLandmarks[0];
                        
                        // 目の間の座標を取得（Landmark 8）
                        const point = landmarks[8];
                        
                        // 外眼角（両目の端）の距離から、擬似的に顔の奥行き（Z）を推測
                        const leftEye = landmarks[33];
                        const rightEye = landmarks[263];
                        const dx = leftEye.x - rightEye.x;
                        const dy = leftEye.y - rightEye.y;
                        const eyeDist = Math.sqrt(dx * dx + dy * dy);
                        
                        // 正規化された座標(0.0〜1.0)を、3D空間の座標(-SCREEN/2 〜 SCREEN/2)にマッピング
                        // カメラは鏡合わせになっているのでX軸の動きに注意
                        
                        const trackingScale = 1.5; // 首の動きに対する感度
                        
                        // X座標（中心0.5からどれだけずれているか。反転させる）
                        const mappedX = (0.5 - point.x) * SCREEN_W * trackingScale;
                        // Y座標（中心0.5からどれだけずれているか。下方向がプラスなので反転）
                        const mappedY = -(point.y - 0.5) * SCREEN_H * trackingScale;
                        // Z座標（目が近い＝eyeDistが大きい＝Zが小さい）
                        // 基準となる目幅を設定し、それに反比例させる
                        const baseEyeDist = 0.15; 
                        const mappedZ = DEFAULT_Z * (baseEyeDist / eyeDist);

                        // 目標位置を更新
                        targetEyePos.set(mappedX, mappedY, mappedZ);
                    } else {
                        // 顔を見失った場合は徐々に正面へ戻す
                        targetEyePos.set(0, 0, DEFAULT_Z);
                    }
                }
            }

            // 2. カメラ位置の補間（ガタつき防止のためのLERP）
            currentEyePos.lerp(targetEyePos, 0.15);

            // 3. オフアクシス投影を適用
            // nearPlaneを1として投影行列を計算。これが「窓」の表面になる
            applyOffAxisProjection(camera, currentEyePos, SCREEN_W, SCREEN_H, 1, 2000);

            // 4. オブジェクトのアニメーション
            floatingObj1.rotation.x += 0.01;
            floatingObj1.rotation.y += 0.01;
            floatingObj2.rotation.x -= 0.005;
            floatingObj2.rotation.y += 0.015;

            // 5. 描画
            renderer.render(scene, camera);
        }

        // --- リサイズ処理 ---
        window.addEventListener('resize', () => {
            SCREEN_H = SCREEN_W * (window.innerHeight / window.innerWidth);
            
            // 部屋のグリッド類のスケールもリサイズに合わせて再調整
            backGrid.scale.z = SCREEN_H / SCREEN_W;
            bottomGrid.position.y = -SCREEN_H / 2;
            topGrid.position.y = SCREEN_H / 2;
            leftGrid.scale.x = BOX_DEPTH / SCREEN_H;
            leftGrid.position.x = -SCREEN_W / 2;
            rightGrid.scale.x = BOX_DEPTH / SCREEN_H;
            rightGrid.position.x = SCREEN_W / 2;

            // 枠線の再生成
            roomGroup.remove(line);
            const newEdges = new THREE.EdgesGeometry(new THREE.BoxGeometry(SCREEN_W, SCREEN_H, BOX_DEPTH));
            const newLine = new THREE.LineSegments(newEdges, new THREE.LineBasicMaterial({ color: 0xffffff, opacity: 0.8, transparent: true }));
            newLine.position.z = -BOX_DEPTH / 2;
            roomGroup.add(newLine);
            
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

    </script>
</body>
</html>
